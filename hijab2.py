# -*- coding: utf-8 -*-
"""Hijab2.ipynb

Automatically generated by Colaboratory. 
"""

import requests
import zipfile
import random
import numpy as np
import cv2
import os
import glob
import shutil
from imutils import paths
import imutils
import matplotlib
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from keras.layers import Dropout
from keras.layers import MaxPool2D
from tensorflow.keras import backend as K

def download_dataset_zip(name_archive, url):
  f=open(rf'{name_archive}.zip',"wb")
  ufr = requests.get(url) #делаем запрос
  f.write(ufr.content) #записываем содержимое в файл; как видите - content запроса
  f.close()

def unpack(name_archive, path):
  fantasy_zip = zipfile.ZipFile(f'{name_archive}.zip')
  fantasy_zip.extractall(path)

def download_image(url_file,path, name_image):
  rows = open(url_file).read().strip().split("\n")
  item = 0
  for row in rows:
    try:
      file_image = open(f'{path}/{name_image}.{item}.jpg','wb')
      file_image.write(requests.get(row).content)
      file_image.close()
      item+=1
    except:
      print(f'Error {item}')

def del_non_img(path):
  for imagePath in paths.list_images(path):
	  delete = False
	  try:
		  image = cv2.imread(imagePath)
		  if image is None:
			  delete = True
	  except:
		  print("Except")
		  delete = True
	  if delete:
		  print("deleting {}".format(imagePath))
		  os.remove(imagePath)

name_archive = 'hijab'
url = "https://github.com/najcardboyz/naja-dataset/archive/master.zip"
path_unpack = '/content/'

download_dataset_zip(name_archive, url)

unpack(name_archive, path_unpack)

shutil.move("/content/naja-dataset-master/dataset-acak-5000", "/content/images")

imageDataPath = sorted(list(paths.list_images('/content/naja-dataset-master/sisa/hijab')))

for img in imageDataPath:
  shutil.move(img, '/content/images/hijab')

imageDataPath = sorted(list(paths.list_images('/content/naja-dataset-master/sisa/nonhijab')))

for img in imageDataPath:
  shutil.move(img, '/content/images/nonhijab')

download_image('nonhibab.txt','/content/download', 'lol')

del_non_img('/content/download')

total=5723

searchedfile = sorted(list(paths.list_images(('/content/download/'))))

for filename in searchedfile:
    im = cv2.imread(filename)
    total+=1
    FaceFileName = "/content/images/nonhijab/nonhijab" + f"{total}.jpg"
    cv2.imwrite(FaceFileName, im)

del_non_img('/content/images/nonhijab')

EPOCHS = 25
INIT_LR = 1e-3
BS = 32
data = []
labels = []
path_data = '/content/images'

imagePaths = sorted(list(paths.list_images(path_data)))
random.seed(42)
random.shuffle(imagePaths)

for imagePath in imagePaths:
	image = cv2.imread(imagePath)
	image = cv2.resize(image, (28, 28))
	image = img_to_array(image)
	data.append(image)
	label = imagePath.split(os.path.sep)[-2]
	label = 1 if label == "hijab" else 0
	labels.append(label)

total=1
for i in labels:
  if i == 0:
    total+=1
print(total)

class Net:
  @staticmethod
  def build(width, height, depth, classes):
    model = Sequential()
    inputShape = (height, width, depth)
    if K.image_data_format() == 'channels_first':
      inputShape = (depth, heigth, width)

    model.add(Conv2D(20, (5,5), padding='same', input_shape=inputShape))
    model.add(Activation("relu"))
    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
    model.add(Flatten())
    model.add(Dense(500))
    model.add(Activation("relu"))
    model.add(Dense(classes))
    model.add(Activation("softmax"))

    #model.add(Conv2D(filters=32, kernel_size=(5,5),padding='same' , activation='relu', input_shape=inputShape))
    #model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))
    #model.add(MaxPool2D(pool_size=(2, 2)))
    #model.add(Dropout(rate=0.25))
    #model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
    #model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
    #model.add(MaxPool2D(pool_size=(2, 2)))
    #model.add(Dropout(rate=0.25))
    #model.add(Flatten())
    #model.add(Dense(256, activation='relu'))
    #model.add(Dropout(rate=0.5))
    #model.add(Dense(classes, activation='softmax'))
    return model

data = np.array(data, dtype="float") / 255.0
labels = np.array(labels)

(trainX, testX, trainY, testY) = train_test_split(data,
	labels, test_size=0.25, random_state=42)

trainY = to_categorical(trainY, num_classes=2)
testY = to_categorical(testY, num_classes=2)

aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,
	height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
	horizontal_flip=True, fill_mode="nearest")

model = Net.build(width=28, height=28, depth=3, classes=2)
opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="binary_crossentropy", optimizer='Adam',
	metrics=["accuracy"])

H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),
	validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,
	epochs=EPOCHS, verbose=1)

plt.style.use("ggplot")
plt.figure()
N = EPOCHS
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), H.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, N), H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy Hijab/Non Hijab")
plt.xlabel("Epoch")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
plt.show()

model.save("my_model28_6.h5")

model = load_model('my_model28_6.h5')

def predict(img,model):
  image = cv2.imread(img)
  orig = image.copy()
  image = cv2.resize(image, (28, 28))
  image = image.astype("float") / 255.0
  image = img_to_array(image)
  image = np.expand_dims(image, axis=0)
  (notHijab, hijab) = model.predict(image)[0]
  label = "Hijab" if hijab > notHijab else "Not Hijab"
  proba = hijab if hijab > notHijab else notHijab
  label = "{}: {:.2f}%".format(label, proba * 100)
  output = imutils.resize(orig, width=400)
  cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,
	0.7, (0, 255, 0), 2)
  plt.imshow(output)
  plt.show()

predict('img6.jpg', model)

predict('img.jpg', model)

predict('img1.jpg', model)

